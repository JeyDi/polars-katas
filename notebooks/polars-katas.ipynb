{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Katas\n",
    "\n",
    "Welcome to some katas\n",
    "\n",
    "The exercises are designed to make you familiar with the following key concept in Polars:\n",
    "\n",
    "* Eager vs lazy\n",
    "* Context and expressions\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "print(pl.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Kata 1: Eager Mode\n",
    "\n",
    "Here is some code to list a bunch of URLs about the ever-famous NYC Yellow Taxi trip data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-{:02d}.parquet\"\n",
    "\n",
    "# we keep the files from Feb 2023 to retain those with the same schema\n",
    "urls = tuple(base.format(month) for month in range(2, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "* Read the first parquet file in the list using `pl.read_parquet`.\n",
    "* Display the top five rows.\n",
    "\n",
    "How long does this take?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Kata 2: Lazy mode\n",
    "\n",
    "Repeat the exercise above, using `pl.scan_parquet` instead. What happens if you run the code? What changes if you scan the whole set of URLs?\n",
    "\n",
    "Write the code to materialize the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Kata 3: The schema\n",
    "\n",
    "Display the `LazyFrame` schema.\n",
    "\n",
    "How is this different from the `pandas` schema?\n",
    "\n",
    "Like `pandas`, `Polars` can `describe` the dataset. Can you do that on a `LazyFrame`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Kata 4: A peek at Expressions\n",
    "\n",
    "Expressions are the \"domain specific language\" (DSL) of Polars. They are a powerful abstraction to describe complex operations over data with an elegant and consistent syntax.\n",
    "\n",
    "Expressions start with a column selector, like `pl.col()` or `pl.all()`. Expressions describe a transformation and are not evaluated on their own. Observe what happens after running this statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.col(\"VendorID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "* What is the type of this object?\n",
    "* What methods are available with method chaining? Use the `dir()` builtin function to list some of them.\n",
    "\n",
    "Expressions can describe operations on multiple columns, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.col(\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Expressions branch from this small core, and use method chaining. For example:\n",
    "\n",
    "* `pl.col(\"a\").max()`\n",
    "* `pl.col(\"date\").dt.year()`\n",
    "* `pl.col(\"name\").str.to_uppercase()`\n",
    "\n",
    "Where `dt` and `str` are examples of `namespaces`, i.e. group of operation that belong to the same data type. There are also namespaces lists, categoricals and struct types - but enough for the moment: now we need to understand how to materialise the results of these operations. On with contexts!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Kata 4: The first context: `pl.select`\n",
    "\n",
    "The `select()` context is used to select columns. Now that we know the existence of the column selector, do the following exercises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pl.scan_parquet(urls[0])\n",
    "# suggestion: you might want to persist this data to disk to avoid being blocked because of sending too many requests\n",
    "# data.sink_parquet(\"../data/trips.parquet\")\n",
    "\n",
    "data = pl.scan_parquet(\"../data/trips.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "1. Select all columns. *Hint: you don't have to write out all names, nor access the `columns` attribute of the dataframe. You might want to take a look at the `pl.all()` expression in the docs...*\n",
    "3. Select all columns except `VendorID`. *Hint: once again, you might want to have a look at `pl.all().exclude()`...*\n",
    "4. Select all columns that contain `amount` in their name. *Hint: you can use regex patterns.*\n",
    "5. Select all `Int64` columns. *Hint: Polars has different datatypes that you can use inside `pl.col`.*\n",
    "6. Select all `Int64` and `Int32` columns.\n",
    "6. Select all datetime and string columns, minus the first column.\n",
    "\n",
    "> **Hint**. To inspect the intermediate steps or results of a query, you can always call the `fetch()` method. It is like a debug statement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Kata 5: The hidden technique of Column Selectors\n",
    "\n",
    "Selecting columns in this way is arguably handy already. However, Polars has a `selectors` module we can use to write even more complex selections.\n",
    "\n",
    "Refer to the [docs](https://docs.pola.rs/py-polars/html/reference/selectors.html#selectors) and repeat the previous kata, plus the following:\n",
    "\n",
    "7. Select all columns that are integers or datetime, except the first one.\n",
    "8. Select all columns that contain an \"ID\" or \"amount\" and are not floating point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars.selectors as cs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Kata 6: Building up expressions\n",
    "\n",
    "It's time to explore expressions more thoroughly. As a starter, we can describe mathematical operations on Expressions like with similar Python objects, such as `numpy` arrays or `pandas` Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select(pl.col(\"trip_distance\") * 1000).fetch(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "This is useful, but breaks the method chain if we want to use other operations. An alternative is to wrap the expression in parenthesis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "1. Multiply the `trip_distance` by 1000 to transform it in metres and name it `trip_distance_meters`.\n",
    "2. Count the number of rows in the data. *Hint: you can use `pl.count()` inside the context.*\n",
    "4. Add `tolls_amount` to `Airport_fee` and name it `total_fees`.\n",
    "5. Compute the average trip distance.\n",
    "6. Select the smallest and largest `tpep_pickup_datetime`. *Hint: this will likely raise an error the first time you run it: remember, there can't be columns with duplicate names in the DataFrame. Note: you don't have to call `pl.col(...).min`: you can just use `pl.max()`*.\n",
    "7. Count the different unique values of `passenger_count`.\n",
    "8. Get the number of unique values of `VendorID` and `RatecodeID`.\n",
    "\n",
    "> **Hint**. You can call `.alias` on an expression to rename the column it generates. Similarly, you can access the `.name.suffix` method to add a suffix. Alternatively, you can name the column using a kwarg notation (i.e., `col=pl.some.expr`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Kata 7: The query plan\n",
    "\n",
    "The `LazyFrame` represents a *Logical Plan*, i.e. a sequence of transformations. It embodies a query, rather than a `DataFrame`. You can inspect this plan when you print the `repr` of the `LazyFrame`.\n",
    "\n",
    "* What method does it suggest to call, to inspect the optimized plan?\n",
    "* Inspect the plan of the last two exercises in the previous kata, comparing the optimised and unoptimised queries.\n",
    "* If you have `graphviz` on your `$PATH`, do the same with `data.show_graph`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Kata 8: the second context: `with_columns`\n",
    "\n",
    "Try to write the expressions in the sixth kata in the same `with_column` context. Do you notice any errors popping up? Can you explain them?\n",
    "\n",
    "Call `explain` on both and compare the query plans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Kata 9: Data types\n",
    "\n",
    "You can change the memory representation of a numeric datatype with `.cast()`.\n",
    "\n",
    "1. Cast the string column into a categorical.\n",
    "2. Cast the integer columns to have the smallest memory footprint.\n",
    "3. Cast the datetime columns to milliseconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Kata 10: Namespaces\n",
    "\n",
    "Polars segregates operations on similar data types behind namespaces, e.g. `str`, `dt`, `list` and `struct`. These are pretty powerful and much more versatile than their `pandas` counterparts, and allow chaining operations without losing performance.\n",
    "\n",
    "1. Cast the `store_and_fwd_flag` column to lowercase.\n",
    "2. Extract the year, month and day of the temporal columns.\n",
    "3. Perform the following steps. *Hint: this can be written as a singular expression. You can always call `.fetch()` to materialise the intermediate results.*\n",
    "    1. Cast the temporal columns to strings.\n",
    "    1. Split them at the ` ` (space) mark\n",
    "    2. Take the first element\n",
    "    3. Split the element at the `-` mark.\n",
    "    4. Cast the result into a struct.\n",
    "    5. Cast the struct into a JSON string with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Kata 11: The third context: `filter`\n",
    "\n",
    "Filtering, combined with the query optimiser, can translate in huge gains. Thanks to the so-called \"predicate pushdown\", query engines can scan parquet files to just read the required rows - thus saving bandwidth and I/O.\n",
    "\n",
    "Filtering is done inside the `filter` context and uses basic Python logical operators. Perform the following filtering operations:\n",
    "\n",
    "1. Passenger count is greater than 3.\n",
    "2. The dropoff hour is the same as the pickup's.\n",
    "2. Trip distance is greater than the average trip distance. *Note: this is the biggest difference between Polars DSL and regular SQL, where such expressions would require separate statements.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Kata 12: The fourth context: `group_by`\n",
    "\n",
    "Aggregations with `group_by` can be elegantly expressed in Polars. An aggregation looks like this: `data.group_by(...).agg(...)`. Inside the brackets, there can be any expression!\n",
    "\n",
    "1. Aggregate by passenger count and compute the average and standard deviation of the trip distance. *Hint: remember, there can't be two columns with the same name!*\n",
    "2. Aggregate by month of departure and compute the mean and standard deviation of the total amount and trip distance.\n",
    "4. Aggregate by vendor ID and just write `\"passenger_count` inside the `.agg` context. What happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Kata 14: Window Functions\n",
    "\n",
    "Window functions can be powerful allies to generate features. This are especially hard with pandas, since they would require creating a new dataframe and performing a join.\n",
    "\n",
    "Window functions are just computed as this: `pl.col(...).mean().over(...)`. They are especially useful for time-based data. For those cases, you can use the powerful `Expr.rolling()` to perform rolling window computations across datetime columns.\n",
    "\n",
    "1. Compute the mean and standard deviation of the price over vendor ID and passenger count.\n",
    "2. Compute the rolling window of the price over a week. Use the pickup time as index. *Note: these operations require you to sort the index, or mark the index as sorted using `set_sorted`.\n",
    "\n",
    "## Kata 15: Manipulating the elements of a list\n",
    "\n",
    "Aggregate the data by vendor and passenger count on trip distance and fare amount. Compute the rolling mean of size 3 over the elements of the list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "# Solutions\n",
    "\n",
    "## Kata 1: Eager mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "url = urls[0]\n",
    "\n",
    "pl.read_parquet(url).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## Kata 2: Lazy mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.scan_parquet(url).head().collect()\n",
    "\n",
    "pl.scan_parquet(urls).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Kata 3: The schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.scan_parquet(url)\n",
    "\n",
    "data.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## Kata 4: Selecting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Select all columns\n",
    "data.select(pl.all())\n",
    "data.select(\"*\")\n",
    "\n",
    "# 2. Select all columns except `VendorID`.\n",
    "data.select(pl.all().exclude(\"VendorID\"))\n",
    "\n",
    "# 3. Select all columns that contain `amount` in their name\n",
    "data.select(pl.col(r\"^*amount$\"))\n",
    "\n",
    "# 4. Select all integer columns.\n",
    "data.select(pl.col(pl.Int64))\n",
    "\n",
    "# 5. Select all numeric columns.\n",
    "data.select(pl.col(pl.NUMERIC_DTYPES))\n",
    "\n",
    "# 6. Select all datetime and string columns.\n",
    "data.select(pl.col(pl.Datetime), pl.col(pl.Utf8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## Kata 5: Columns selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Select all columns\n",
    "data.select(cs.all())\n",
    "\n",
    "# 2. Select all columns except `VendorID`.\n",
    "data.select(~cs.by_name(\"VendorID\"))\n",
    "\n",
    "# 3. Select all columns that contain `amount` in their name\n",
    "data.select(cs.contains(\"amount\"))\n",
    "data.select(cs.matches(\"*amount\"))\n",
    "\n",
    "# 4. Select all integer columns.\n",
    "data.select(cs.integer())\n",
    "\n",
    "# 5. Select all numeric columns.\n",
    "data.select(cs.numeric())\n",
    "\n",
    "# 6. Select all datetime and string columns.\n",
    "data.select(cs.temporal(), cs.string())\n",
    "data.select(cs.temporal() | cs.string())\n",
    "\n",
    "# 7. Select all columns that are integers or datetime, except the first one.\n",
    "data.select(cs.integer() - cs.first() | cs.temporal())\n",
    "\n",
    "# 8. Select all columns that contain an \"ID\" or \"amount\" and are not floating point numbers.\n",
    "data.select(cs.contains((\"ID\", \"Amount\")) | ~cs.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "## Kata 6: Introduction to expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Multiply the `trip_distance` by 1000 to cast it in metres.\n",
    "data.with_columns(trip_distance_meters=pl.col(\"trip_distance\") * 1000)\n",
    "data.with_columns(pl.col(\"trip_distance\").mul(1000).alias(\"trip_distance_meters\"))\n",
    "data.with_columns(pl.col(\"trip_distance\").mul(1000).name.suffix(\"_meters\"))\n",
    "\n",
    "# 2. Add `tolls_amount`, `Airport_fee` and name it `total_fees`.\n",
    "data.with_columns(total_fees=pl.col(\"tolls_amount\") + pl.col(\"Airport_fee\"))\n",
    "\n",
    "#\n",
    "data.select(\n",
    "    pl.min(\"tpep_pickup_datetime\").name.suffix(\"_min\"),\n",
    "    pl.max(\"tpep_pickup_datetime\").name.suffix(\"_max\"),\n",
    ").collect()\n",
    "\n",
    "# 3. Compute the ratio between `tip`, `mta_tax` and `fare_amount` over `total_amount`.\n",
    "data.with_columns(\n",
    "    pl.col(\"tip\", \"mta_tax\", \"fare_amount\").truediv(\"total_amount\").name.suffix(\"_pct\")\n",
    ")\n",
    "\n",
    "# 4. Compute the average trip distance.\n",
    "data.with_columns(pl.col(\"trip_distance\").mean())\n",
    "\n",
    "# 5. Count the unique values of `passenger_count`.\n",
    "data.with_columns(pl.col(\"passenger_count\").value_counts())\n",
    "\n",
    "# 6. Get the unique values of `VendorID` and `RatecodeID`.\n",
    "data.with_columns(pl.col(\"VendorID\", \"RatecodeID\").n_unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## Kata 7: The query plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_change = (\n",
    "    pl.col(\"tip_amount\", \"mta_tax\", \"fare_amount\")\n",
    "    .truediv(\"total_amount\")\n",
    "    .name.suffix(\"_pct\")\n",
    ")\n",
    "\n",
    "data.with_columns(percentage_change).explain(optimized=False)\n",
    "data.with_columns(percentage_change).explain(optimized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "## Kata 8: Chaining multiple contexts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.with_columns(\n",
    "    pl.col(\"trip_distance\").mul(1000).name.suffix(\"_meters\"),\n",
    "    pl.col(\"tolls_amount\").add(pl.col(\"Airport_fee\")).alias(\"total_fees\"),\n",
    ").with_columns(\n",
    "    pl.col(\"tip_amount\", \"total_fees\", \"mta_tax\", \"fare_amount\")\n",
    "    .truediv(pl.col(\"total_amount\"))\n",
    "    .name.suffix(\"_pct\")\n",
    ").explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "## Kata 9: Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select(\n",
    "    cs.temporal().as_expr().cast(pl.Date),\n",
    "    cs.string().as_expr().cast(pl.Categorical),\n",
    "    cs.numeric().shrink_dtype(),\n",
    ").fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "## Kata 10: Namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select(\n",
    "    cs.temporal()\n",
    "    .as_expr()\n",
    "    .cast(pl.Utf8)\n",
    "    .str.split(\" \")\n",
    "    .list.first()\n",
    "    .str.split(\"-\")\n",
    "    .list.to_struct()\n",
    "    .struct.json_encode()\n",
    ").fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "## Kata 11: The third context: `filter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.filter(pl.count(\"passenger_count\") > 3).fetch()\n",
    "\n",
    "data.filter(pl.col(\"tpep_pickup_datetime\") == pl.col(\"tpep_pickup_datetime\")).fetch()\n",
    "\n",
    "(data.lazy().filter(pl.col(\"trip_distance\") > pl.col(\"trip_distance\").mean()).fetch())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "## Kata 12: The fourth context: `group_by`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    data.group_by(\"passenger_count\")\n",
    "    .agg(\n",
    "        pl.col(\"trip_distance\").mean().name.suffix(\"_mean\"),\n",
    "        pl.col(\"trip_distance\").std().name.suffix(\"_std\"),\n",
    "    )\n",
    "    .fetch()\n",
    ")\n",
    "\n",
    "(\n",
    "    data.group_by(pl.col(\"tpep_pickup_datetime\").dt.month())\n",
    "    .agg(\n",
    "        pl.col(\"total_amount\", \"trip_distance\").mean().name.suffix(\"_mean\"),\n",
    "        pl.col(\"total_amount\", \"trip_distance\").std().name.suffix(\"_std\"),\n",
    "    )\n",
    "    .fetch()\n",
    ")\n",
    "\n",
    "(data.group_by(\"VendorID\").agg(\"passenger_count\").fetch())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "## Kata 14: Window functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    data.with_columns(\n",
    "        pl.mean(\"total_amount\")\n",
    "        .over(\"VendorID\", \"passenger_count\")\n",
    "        .name.suffix(\"_over_vendorid_and_passenger_count\")\n",
    "    ).fetch()\n",
    ")\n",
    "\n",
    "(\n",
    "    data.set_sorted(\"tpep_pickup_datetime\")\n",
    "    .with_columns(\n",
    "        pl.mean(\"total_amount\")\n",
    "        .rolling(\"tpep_pickup_datetime\", period=\"1w\")\n",
    "        .name.suffix(\"_rolling\")\n",
    "    )\n",
    "    .fetch()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## Kata 15: List manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    data.group_by(\"VendorID\", \"passenger_count\")\n",
    "    .agg(\"trip_distance\", \"fare_amount\")\n",
    "    .with_columns(\n",
    "        pl.col(\"trip_distance\").list.eval(pl.element().rolling_mean(window_size=3))\n",
    "    )\n",
    "    .fetch()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
